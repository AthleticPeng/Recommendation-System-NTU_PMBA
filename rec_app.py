import streamlit as st
import pandas as pd
import numpy as np
from collections import Counter
from sklearn.metrics.pairwise import cosine_similarity

# ==== æ¨¡æ“¬è³‡æ–™ ====
data = {
    'user_id': [1, 1, 1, 1, 1,     # å°æ˜
                2, 2, 2, 2,        # å°ç¾
                3, 3, 3, 3, 3,     # å°å®‰
                4, 4, 4, 4,        # å°å¤©
                5, 5, 5,           # å°æ—
                6, 6, 6, 6, 6, 6,  # å°è‰¾
                3, 4, 2],          # é¡å¤–é—œè¯äº¤é›†
    'item_id': [1, 2, 3, 7, 4,     # å°æ˜ï¼ˆ+ä¸€æ¬¡é¤Šç”Ÿï¼‰
                1, 4, 5, 2,        # å°ç¾ï¼ˆitem 5 èª¿æˆ 2ï¼‰
                1, 2, 3, 5, 6,     # å°å®‰
                1, 5, 6, 7,        # å°å¤©ï¼ˆäº¤é›†æ“´å±•ï¼‰
                1, 2, 3,           # å°æ—
                6, 8, 2, 5, 3, 4,  # å°è‰¾
                8, 8, 8],          # åŠ å…¥å°å®‰ã€å°å¤©ã€å°ç¾çœ‹éã€Šæ±äº¬è‡ªç”±è¡Œã€‹
    'rating':  [5, 3, 4, 3, 4,     # å°æ˜
                4, 5, 2, 3,        # å°ç¾ï¼ˆitem 5 ç‚º 2ï¼‰
                5, 4, 4, 3, 5,     # å°å®‰
                5, 3, 4, 4,        # å°å¤©
                5, 5, 2,           # å°æ—
                2, 4, 4, 2, 5, 3,  # å°è‰¾
                3, 4, 4]           # é¡å¤–äº¤é›†ï¼ˆæ±äº¬è‡ªç”±è¡Œï¼‰
}

user_names = {1: 'å°æ˜', 2: 'å°ç¾', 3: 'å°å®‰', 4: 'å°å¤©', 5: 'å°æ—', 6: 'å°è‰¾'}
item_names = {
    1: 'è¼é”ä¹‹é“', 2: 'å¤±æ§çš„ç„¦æ…®ä¸–ä»£', 3: 'é€†æ€ç¶­', 4: 'åŸå§‹ç¢¼',
    5: 'å‡è¦–å¤ªé™½ï¼šé¢å°æ­»äº¡ææ‡¼', 6: 'æ€è€ƒçš„è—è¡“',
    7: 'ä¸€æ¬¡è®€æ‡‚é¤Šç”Ÿç²¾é«“', 8: 'æ±äº¬è‡ªç”±è¡Œçµ‚æ¥µæŒ‡å—'
}

# ==== æº–å‚™è³‡æ–™ ====
df = pd.DataFrame(data)
user_item_matrix = df.pivot(index='user_id', columns='item_id', values='rating')

# é¡¯ç¤ºçŸ©é™£
st.markdown("### ğŸ”¢ ä½¿ç”¨è€…-æ›¸ç±è©•åˆ†çŸ©é™£ï¼ˆNaN è¡¨ç¤ºæœªè©•åˆ†ï¼‰")
matrix_named = user_item_matrix.copy()
matrix_named.index = [user_names[i] for i in matrix_named.index]
matrix_named.columns = [item_names[i] for i in matrix_named.columns]
# å‰µå»ºä¸€å€‹æ–°çš„ DataFrameï¼Œå°‡ NaN æ›¿æ›ç‚º None (é€™åœ¨å¤§å¤šæ•¸ç‰ˆæœ¬ä¸­æ‡‰è©²å¯è¡Œ)
matrix_display = matrix_named.copy()
matrix_display = matrix_display.where(pd.notnull(matrix_display), None)
st.dataframe(matrix_display)

# ==== Streamlit App ====
st.title("ğŸ“š User-Based vs Item-Based å”åŒéæ¿¾æ¨è–¦ç³»çµ±")
st.write("å¯ä»¥åˆ‡æ›æ¨è–¦æ–¹å¼ä¸¦é¸æ“‡ä½¿ç”¨è€…ï¼ŒæŸ¥çœ‹æ¨è–¦çµæœ")

user_display = {v: k for k, v in user_names.items()}
selected_user_name = st.selectbox("é¸æ“‡ä¸€ä½ä½¿ç”¨è€…ï¼š", list(user_display.keys()))
selected_user_id = user_display[selected_user_name]

method = st.radio("é¸æ“‡æ¨è–¦æ–¹æ³•ï¼š", ["Item-Based Filtering", "User-Based Filtering"])

# ==== Item-based Filtering ====
if method == "Item-Based Filtering":
    target_ratings = user_item_matrix.loc[selected_user_id]
    liked_items = target_ratings[target_ratings >= 4].index.tolist()

    if not liked_items:
        st.warning("æ­¤ç”¨æˆ¶ç›®å‰æ²’æœ‰è©•åˆ† â‰¥ 4 çš„æ›¸ï¼Œç„¡æ³•é€²è¡Œæ¨è–¦ã€‚")
        st.stop()

    st.markdown(f"### ğŸ‘ {selected_user_name} å–œæ­¡çš„æ›¸ï¼ˆè©•åˆ† â‰¥ 4ï¼‰ï¼š")
    for i in liked_items:
        st.write(f"- {item_names[i]}")

    item_similarity_matrix = pd.DataFrame(
        cosine_similarity(user_item_matrix.T.fillna(0)),
        index=user_item_matrix.columns,
        columns=user_item_matrix.columns
    )

    similar_items = []
    top_k_per_item = st.slider("æ¯æœ¬å–œæ­¡çš„æ›¸æ‰¾å¹¾æœ¬ç›¸ä¼¼æ›¸ï¼Ÿ", 1, 5, 3)

    for item_id in liked_items:
        similar = item_similarity_matrix[item_id].drop(index=item_id)
        top_sim = similar.sort_values(ascending=False).head(top_k_per_item)
        st.markdown(f"#### èˆ‡ã€Š{item_names[item_id]}ã€‹ç›¸ä¼¼çš„æ›¸ï¼š")
        for sim_item_id, score in top_sim.items():
            st.write(f"â†’ {item_names[sim_item_id]}ï¼ˆç›¸ä¼¼åº¦ï¼š{score:.2f}ï¼‰")
            similar_items.append(sim_item_id)

    recommend_counts = Counter(similar_items)
    already_read = target_ratings[target_ratings > 0].index.tolist()
    filtered = {i: c for i, c in recommend_counts.items() if i not in already_read}

    top_n = st.slider("é¡¯ç¤ºæ¨è–¦å¹¾æœ¬æ›¸ï¼š", 1, 5, 2)
    final_recommend = sorted(filtered.items(), key=lambda x: x[1], reverse=True)[:top_n]

    st.markdown("### ğŸ¯ æœ€çµ‚æ¨è–¦æ›¸ç±ï¼š")
    if not final_recommend:
        st.info("ç„¡å¯æ¨è–¦çš„æ–°æ›¸ï¼ˆå¯èƒ½å·²ç¶“å…¨çœ‹éäº† ğŸ˜…ï¼‰")
    else:
        for i, count in final_recommend:
            st.success(f"{item_names[i]}ï¼ˆè¢«æ¨è–¦æ¬¡æ•¸ï¼š{count}ï¼‰")

# ==== User-based Filtering ====
else:
    def pearson_correlation(user1, user2, matrix):
        common = (matrix.loc[user1] > 0) & (matrix.loc[user2] > 0)
        if common.sum() == 0:
            return 0
        u1 = matrix.loc[user1, common]
        u2 = matrix.loc[user2, common]
        u1_mean = u1.mean()
        u2_mean = u2.mean()
        num = ((u1 - u1_mean) * (u2 - u2_mean)).sum()
        denom = np.sqrt(((u1 - u1_mean)**2).sum()) * np.sqrt(((u2 - u2_mean)**2).sum())
        return num / denom if denom != 0 else 0

    similarities = {
        other: pearson_correlation(selected_user_id, other, user_item_matrix.fillna(0))
        for other in user_item_matrix.index if other != selected_user_id
    }
    top2 = sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:2]
    ref_users = [u for u, _ in top2]
    ref_sims = [s for _, s in top2]

    st.markdown("### ğŸ‘¥ ç›¸ä¼¼ä½¿ç”¨è€…ï¼š")
    for u, s in top2:
        st.write(f"{user_names[u]}ï¼ˆç›¸ä¼¼åº¦ï¼š{s:.4f}ï¼‰")

    target_ratings = user_item_matrix.loc[selected_user_id]
    weighted_sum = pd.Series(0.0, index=user_item_matrix.columns)
    for uid, sim in zip(ref_users, ref_sims):
        # weighted_sum += user_item_matrix.loc[uid].fillna(0) * sim
        weighted_sum += user_item_matrix.loc[uid].fillna(0)

    unrated = target_ratings[target_ratings.isna()].index
    predictions = weighted_sum[unrated].sort_values(ascending=False).head(3)

    st.markdown("### ğŸ¯ æœ€çµ‚æ¨è–¦æ›¸ç±ï¼ˆåŠ ç¸½åˆ†æ•¸æœ€é«˜ï¼‰ï¼š")
    for item_id, score in predictions.items():
        st.success(f"{item_names[item_id]}ï¼ˆåŠ ç¸½åˆ†æ•¸ï¼š{score:.2f}ï¼‰")
